{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a151cf",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac37088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "assert sys.version_info >=(3, 7)\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from util_func import *\n",
    "import imutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edd470",
   "metadata": {},
   "source": [
    "## Exercise 1 \n",
    "Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use \"lena.jfif\" as the input image.\n",
    "- Use external libraries imutils.\n",
    "- Modify the transformation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e18240b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imutils\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "rotated = imutils.rotate_bound(img, 45)\n",
    "cv.imshow(\"Imutils Rotation\", rotated)\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7dd5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "# Determine the center of the image\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "\n",
    "# Define the rotation angle in degrees (positive for counter-clockwise)\n",
    "angle = 45\n",
    "\n",
    "# Get the rotation matrix\n",
    "M = cv.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "# Calculate the new image dimensions after rotation\n",
    "cos_theta = abs(M[0, 0])\n",
    "sin_theta = abs(M[0, 1])\n",
    "new_w = int((h * sin_theta) + (w * cos_theta))\n",
    "new_h = int((h * cos_theta) + (w * sin_theta))\n",
    "\n",
    "# Adjust the rotation matrix to account for translation and padding\n",
    "M[0, 2] += (new_w - w) // 2\n",
    "M[1, 2] += (new_h - h) // 2\n",
    "\n",
    "# Perform the rotation with padding to avoid cropping\n",
    "r_img = cv.warpAffine(img, M, (new_w, new_h))\n",
    "\n",
    "# Display the original and rotated images\n",
    "cv.imshow(\"Rotated Image\", r_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7757349",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Use the images with titles: \"flower.jfif\" and \"native-bee.png\". I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are cv.bitwise_and(), cv.bitwise_or() and cv.bitwise_not(). You need to use cv.threshold function to segment the flower. Please refer to online documentation for more info. The result should resemble the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64b4523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load two images\n",
    "img1 = cv.imread('images/native-bee.png')\n",
    "img2 = cv.imread('images/flower.jfif')\n",
    "\n",
    "assert img1 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "assert img2 is not None, \"file could not be read, check with os.path.exists()\"\n",
    "\n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    "\n",
    "# Now create a mask of logo and create its inverse mask also\n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "# Put logo in ROI and modify the main image\n",
    "dst = cv.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "cv.imshow('res',img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03262b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "kernel2 = np.array([[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1], [-1, -1, 25, -1, -1],[-1, -1, -1, -1, -1], [-1, -1, -1, -1, -1]])\n",
    "\n",
    "sharpen = cv.filter2D(img1, -1, kernel)\n",
    "sharpen2 = cv.filter2D(img1, -1, kernel2)\n",
    "\n",
    "\n",
    "cv.imshow(\"sharpen\", sharpen)\n",
    "cv.imshow(\"sharpen2\", sharpen2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c15fe",
   "metadata": {},
   "source": [
    "5x5 has a wider aperture which makes it enhances the edges and details more aggresive than 3x3. It enhances larger features and edges in the image compared to 3x3 but it also introduced more noises compared to 3x3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef2498",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Apply different image smoothing techniques (e.g. average filter, Gaussian kernel and median filter) on 'noise_lena.jpg' and display the resulting images after the convolution. Comment on the outcomes and deduce the type of noise present on the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31a1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "image_path = \"images/noise_lena.jpg\"\n",
    "image = cv.imread(image_path)\n",
    "\n",
    "# Apply average filter (blur)\n",
    "average_filtered = cv.blur(image, (5, 5))\n",
    "\n",
    "# Apply Gaussian filter\n",
    "gaussian_filtered = cv.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Apply median filter\n",
    "median_filtered = cv.medianBlur(image, 5)\n",
    "\n",
    "# Display the original and filtered images\n",
    "cv.imshow(\"Original Image\", image)\n",
    "cv.imshow(\"Average Filtered\", average_filtered)\n",
    "cv.imshow(\"Gaussian Filtered\", gaussian_filtered)\n",
    "cv.imshow(\"Median Filtered\", median_filtered)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda9bad0",
   "metadata": {},
   "source": [
    "### Average Filtered\n",
    "- looks blurrier and smooth\n",
    "- Gaussian noise\n",
    "\n",
    "### Median Filtered\n",
    "- shows fewer noise spots and retains the overall structure well\n",
    "- impulse noise\n",
    "\n",
    "### Gaussian Filtered\n",
    "- show some noise reduction\n",
    "- Gaussian noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095a1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
